{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zcXfSmdqcLXixbSOYluz_-e37HwEXaEZ",
      "authorship_tag": "ABX9TyMVUvNXv+1IfFdOqOembJCs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hatefap/CrackingTheInterview/blob/master/bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGr6knQwWZCa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95WZky0oWmRx",
        "outputId": "5c4e78a5-a9c1-4726-c1a3-518ecfc7fc5b"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "np.random.seed(101)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Hyva6zWo6z"
      },
      "source": [
        "farsi_path = \"drive/MyDrive/final_final.csv\"\n",
        "english_path = \"drive/MyDrive/my_final_english_hate.csv\"\n",
        "eng = pd.read_csv(english_path)\n",
        "farsi = pd.read_csv(farsi_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "T38_hVj9wCwk",
        "outputId": "4a653678-c38c-4b27-c8df-9983164aa5d0"
      },
      "source": [
        "farsi.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>ref1</th>\n",
              "      <th>ref2</th>\n",
              "      <th>link</th>\n",
              "      <th>norm_text</th>\n",
              "      <th>google</th>\n",
              "      <th>mbart</th>\n",
              "      <th>ref3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>بچه های عزیز این کشتزار منو بلاک کرده یکی که د...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>https://twitter.com/DrErovay/status/1249849840...</td>\n",
              "      <td>بچه‌های عزیز این کشتزار منو بلاک کرده یکی که د...</td>\n",
              "      <td>Children's Menu block the field of view of one...</td>\n",
              "      <td>My dear children, I've been blocked on this fa...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>سیاسیون محترم از  نمایندگان گرفته تا  شهردارا...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>https://twitter.com/atefeh heidari/status/1007...</td>\n",
              "      <td>سیاسیون محترم از نمایندگان گرفته تا شهرداران ...</td>\n",
              "      <td>Distinguished delegates politicians to munici...</td>\n",
              "      <td>From respectable politicians to elected offici...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>با اعدام مخالفم \\n\\nکاش راهکاری برای نابودی و ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>https://twitter.com/fariborz c/status/10124857...</td>\n",
              "      <td>با اعدام مخالفم \\n\\nکاش راهکاری برای نابودی و ...</td>\n",
              "      <td>I disagree with execution\\n\\nIf only way to an...</td>\n",
              "      <td>With the execution of my opponent, I wish ther...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>دونوع آدم داریم : یکی اونکه هیچی به کیرش نیست ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>https://twitter.com/llil ili lill/status/10190...</td>\n",
              "      <td>دونوع آدم داریم: یکی اونکه هیچی به کیرش نیست و...</td>\n",
              "      <td>There are two types of people: one Avnkh nothi...</td>\n",
              "      <td>There are two types of people: There's the one...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>هيچ زنداني بدتر از ،دختر بودن، نيست....</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>https://twitter.com/virgoOoOol/status/10233572...</td>\n",
              "      <td>هیچ زندانی بدتر از، دختر بودن، نیست ….</td>\n",
              "      <td>No prisoners worse, the girl is not ....</td>\n",
              "      <td>There is no prison worse than being a girl...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... ref3\n",
              "0   0  ...  1.0\n",
              "1   1  ...  0.0\n",
              "2   2  ...  1.0\n",
              "3   3  ...  0.0\n",
              "4   4  ...  0.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCuIVf9hwJDx"
      },
      "source": [
        "farsi = farsi[['google', 'mbart', 'ref3']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YliCx8ApWxXH",
        "outputId": "fb87c7c2-fffc-4c99-f44d-70ab9d03f995"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htiOeTxCvf5z"
      },
      "source": [
        "def deEmojify(row):\n",
        "    text = row.tweet\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6lFbwSUYvjhZ",
        "outputId": "5fb8bba5-d92a-4298-e6ab-76e52b36c6d5"
      },
      "source": [
        "eng = eng.drop(\"Unnamed: 0\", axis=1)\n",
        "eng['tweet'] = eng.apply(deEmojify, axis=1)\n",
        "eng = eng.sample(frac=1).reset_index(drop=True)\n",
        "eng.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @USER You a hoe if you give your number to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Best rider? That goes to a blaxican.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER hes just a friggin idiot that can say an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That niggas retarded</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why is my mother bothering me about the trash?...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  class\n",
              "0  RT @USER You a hoe if you give your number to ...      1\n",
              "1               Best rider? That goes to a blaxican.      0\n",
              "2  @USER hes just a friggin idiot that can say an...      1\n",
              "3                               That niggas retarded      1\n",
              "4  Why is my mother bothering me about the trash?...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyEF-ucJwwn3"
      },
      "source": [
        "def deEmojifyGoogle(row):\n",
        "    text = row.google\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvnT_eE0w8KP"
      },
      "source": [
        "def deEmojifyMbart(row):\n",
        "    text = row.mbart\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KX0wS1WxvqfG",
        "outputId": "d79bcebc-fa9d-4729-fe8e-5e82e46a2cb7"
      },
      "source": [
        "farsi = farsi.dropna()\n",
        "farsi['google'] = farsi.apply(deEmojifyGoogle, axis=1)\n",
        "farsi['mbart'] = farsi.apply(deEmojifyMbart, axis=1)\n",
        "farsi = farsi.sample(frac=1).reset_index(drop=True)\n",
        "farsi.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>google</th>\n",
              "      <th>mbart</th>\n",
              "      <th>ref3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bvdymyr and tell us that we're ten more comfor...</td>\n",
              "      <td>We were like, we're going to make it easier fo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We happened upon the streets Gzart.\\nA city\\nW...</td>\n",
              "      <td>We sat in that alley that had fallen over — it...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The number of male and female have a very diff...</td>\n",
              "      <td>The number of boys and girls doesn't seem that...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If Arab students are female doctor Persian He ...</td>\n",
              "      <td>If you're an Arab student, the Ph.D. student o...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was jumping up Qtlm a hedgehog.\\nThe prayer ...</td>\n",
              "      <td>It wasn't long before I was going to be the ki...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              google  ... ref3\n",
              "0  Bvdymyr and tell us that we're ten more comfor...  ...  0.0\n",
              "1  We happened upon the streets Gzart.\\nA city\\nW...  ...  0.0\n",
              "2  The number of male and female have a very diff...  ...  0.0\n",
              "3  If Arab students are female doctor Persian He ...  ...  0.0\n",
              "4  I was jumping up Qtlm a hedgehog.\\nThe prayer ...  ...  0.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_Sx7Cp7-v-RG",
        "outputId": "0db9ec3a-bf30-4c54-ae32-73dcaa329d49"
      },
      "source": [
        "eng.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @USER You a hoe if you give your number to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Best rider? That goes to a blaxican.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER hes just a friggin idiot that can say an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That niggas retarded</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why is my mother bothering me about the trash?...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  class\n",
              "0  RT @USER You a hoe if you give your number to ...      1\n",
              "1               Best rider? That goes to a blaxican.      0\n",
              "2  @USER hes just a friggin idiot that can say an...      1\n",
              "3                               That niggas retarded      1\n",
              "4  Why is my mother bothering me about the trash?...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goBt-tUsymKq"
      },
      "source": [
        "x_train = eng[['tweet']]\n",
        "y_train = eng[['class']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80MaLsDIz4nL"
      },
      "source": [
        "x_google = farsi[['google']]\n",
        "y_google = farsi[['ref3']]\n",
        "x_mbart = farsi[['mbart']]\n",
        "y_mbart = farsi[['ref3']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siyiaZjanzvB"
      },
      "source": [
        "y_google.columns = ['class']\n",
        "y_mbart.columns = ['class']  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFIlb-bj0Nzm",
        "outputId": "6e46a4db-086c-4375-a041-3a4327ca3cfa"
      },
      "source": [
        "x_train['tweet']    = [entry.lower() for entry in x_train['tweet']]\n",
        "x_google['google'] = [entry.lower() for entry in x_google['google']]\n",
        "x_mbart['mbart']   = [entry.lower() for entry in x_mbart['mbart']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3ELYlLu2Iae",
        "outputId": "58def32d-81d2-42e5-aa53-4b68191802fa"
      },
      "source": [
        "x_train['tweet']    = [word_tokenize(entry) for entry in x_train['tweet']]\n",
        "x_google['google'] = [word_tokenize(entry) for entry in x_google['google']]\n",
        "x_mbart['mbart']   = [word_tokenize(entry) for entry in x_mbart['mbart']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z3noz2U2Ty5"
      },
      "source": [
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF9rVPpY9k5L"
      },
      "source": [
        "def clean(pd, name):\n",
        "  for index,entry in enumerate(pd[name]):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    pd.loc[index,'text_final'] = str(Final_words)\n",
        "  return pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUt9lQg-9-1I",
        "outputId": "5916d8cd-5bbc-4031-e372-36d8a96878aa"
      },
      "source": [
        "x_train = clean(x_train, 'tweet')\n",
        "x_google = clean(x_google, 'google')\n",
        "x_mbart = clean(x_mbart, 'mbart')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9rABBKc86zf"
      },
      "source": [
        "tune_X_google, Test_X_google, tune_Y_google, Test_Y_google = model_selection.train_test_split(x_google['text_final'],y_google ,test_size=0.4, random_state=101)\n",
        "\n",
        "tune_X_mbart, Test_X_mbart, tune_Y_mbart, Test_Y_mbart  = model_selection.train_test_split(x_mbart['text_final'],y_mbart ,test_size=0.4, random_state=101)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqT29UdXGNG8"
      },
      "source": [
        "tune_Y_google = tune_Y_google.astype(dtype=\"int\")  \n",
        "Test_Y_google = Test_Y_google.astype(dtype=\"int\")\n",
        "tune_Y_mbart = tune_Y_mbart.astype(dtype=\"int\")\n",
        "Test_Y_mbart = Test_Y_mbart.astype(dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9TM5jtNbk6N",
        "outputId": "b41439d6-0efe-4e9c-8762-bd748fc6bb28"
      },
      "source": [
        "tune_X_google"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3214    ['guy', 'monster', 'time', 'pass', 'demon', 'p...\n",
              "1262    ['late', 'late', 'cable', 'direct', 'czech', '...\n",
              "2069    ['khbrayn', 'week', 'hell', 'late', 'hdadksyf'...\n",
              "322     ['know', 'manvk', 'khodabakhshian', 'go', 'mea...\n",
              "4294    ['reed', 'ya', 'club', 'sorry', 'sorry', 'say'...\n",
              "                              ...                        \n",
              "4171    ['ready', 'help', 'account', 'number', 'announ...\n",
              "599           ['simple', 'nemishe', 'little', 'shrewish']\n",
              "1361    ['pretty', 'cool', 'one', 'hour', 'delete', 'k...\n",
              "1547    ['nothing', 'never', 'wan', 'na', 'n', 'pituit...\n",
              "4959                                    ['think', 'like']\n",
              "Name: text_final, Length: 3120, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQEOkrw1Z2zK",
        "outputId": "f69d884b-4314-4777-cdf4-d8e11e83cc13"
      },
      "source": [
        "x_train = x_train['text_final']\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        ['rt', 'user', 'hoe', 'give', 'number', 'anoth...\n",
              "1                      ['best', 'rider', 'go', 'blaxican']\n",
              "2        ['user', 'he', 'friggin', 'idiot', 'say', 'any...\n",
              "3                                      ['nigga', 'retard']\n",
              "4        ['mother', 'bother', 'trash', 'day', 'leave', ...\n",
              "                               ...                        \n",
              "10848                                   ['user', 'faggot']\n",
              "10849    ['rangzen', 'people', 'stop', 'fake', 'activis...\n",
              "10850    ['user', 'orange', 'menace', 'user', 'side', '...\n",
              "10851                           ['like', 'bitch', 'nigga']\n",
              "10852    ['user', 'lmao', 'yes', 'kind', 'like', 'ghett...\n",
              "Name: text_final, Length: 10853, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhawqCFFOKhb"
      },
      "source": [
        "max_features = 500\n",
        "alpha = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1D2s_3NN1Lb"
      },
      "source": [
        "Tfidf_vect_x_train = TfidfVectorizer(max_features=max_features)\n",
        "Tfidf_vect_x_train.fit(x_train)\n",
        "\n",
        "Train_X_Tfidf      = Tfidf_vect_x_train.transform(x_train)\n",
        "tune_google_Tfidf  = Tfidf_vect_x_train.transform(tune_X_google)\n",
        "tune_mbart_Tfidf   = Tfidf_vect_x_train.transform(tune_X_mbart)\n",
        "test_google_Tfidf  = Tfidf_vect_x_train.transform(Test_X_google)\n",
        "Test_mbart_Tfidf   = Tfidf_vect_x_train.transform(Test_X_mbart)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4LCt-KsGxQO",
        "outputId": "e60da6be-eeca-427c-b513-b830b6ad239d"
      },
      "source": [
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkZZssZefX6y"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqi-l36seqXI",
        "outputId": "6a615cc3-7255-4293-a7d8-5f6833a27b98"
      },
      "source": [
        "predictions_NB = Naive.predict(tune_google_Tfidf)\n",
        "print(classification_report(tune_Y_google , predictions_NB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      2644\n",
            "           1       0.35      0.24      0.28       476\n",
            "\n",
            "    accuracy                           0.82      3120\n",
            "   macro avg       0.61      0.58      0.59      3120\n",
            "weighted avg       0.79      0.82      0.80      3120\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OTcxAV7jyGz",
        "outputId": "2a2d1d94-7e59-413c-ef45-2450fa844c64"
      },
      "source": [
        "# x_train = x_train.append(tune_X_google)\n",
        "# y_train = y_train.append(tune_Y_google)\n",
        "# x_train.reset_index(inplace=True, drop=True)\n",
        "# y_train.reset_index(inplace=True, drop=True)\n",
        "# x_train\n",
        "x_train = x_train.append(tune_X_mbart)\n",
        "y_train = y_train.append(tune_Y_mbart)\n",
        "x_train.reset_index(inplace=True, drop=True)\n",
        "y_train.reset_index(inplace=True, drop=True)\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        ['rt', 'user', 'hoe', 'give', 'number', 'anoth...\n",
              "1                      ['best', 'rider', 'go', 'blaxican']\n",
              "2        ['user', 'he', 'friggin', 'idiot', 'say', 'any...\n",
              "3                                      ['nigga', 'retard']\n",
              "4        ['mother', 'bother', 'trash', 'day', 'leave', ...\n",
              "                               ...                        \n",
              "13968    ['go', 'help', 'get', 'account', 'number', 'sa...\n",
              "13969                                           ['simple']\n",
              "13970    ['really', 'fun', 'spend', 'hour', 'diving', '...\n",
              "13971                               ['say', 'pray', 'god']\n",
              "13972                                    ['think', 'coma']\n",
              "Name: text_final, Length: 13973, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QFGyaCR8m3-e",
        "outputId": "470b5728-646c-462d-e760-bf928a679f8b"
      },
      "source": [
        "# y_train\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13968</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13969</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13970</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13971</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13972</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13973 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class\n",
              "0          1\n",
              "1          0\n",
              "2          1\n",
              "3          1\n",
              "4          0\n",
              "...      ...\n",
              "13968      1\n",
              "13969      1\n",
              "13970      0\n",
              "13971      0\n",
              "13972      0\n",
              "\n",
              "[13973 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul4ij5-mfG6g"
      },
      "source": [
        "# Tfidf_vect_x_train = TfidfVectorizer(max_features=max_features)\n",
        "# Tfidf_vect_x_train.fit(x_train)\n",
        "# Train_X_Tfidf      = Tfidf_vect_x_train.transform(x_train)\n",
        "\n",
        "\n",
        "Tfidf_vect_x_train = TfidfVectorizer(max_features=max_features)\n",
        "Tfidf_vect_x_train.fit(x_train)\n",
        "Train_X_Tfidf      = Tfidf_vect_x_train.transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAkjKrcCpZRI"
      },
      "source": [
        "# test_google_Tfidf  = Tfidf_vect_x_train.transform(Test_X_google)\n",
        "\n",
        "test_mbart_Tfidf  = Tfidf_vect_x_train.transform(Test_X_mbart)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNdI4zN3kYNk",
        "outputId": "3ef1364d-3a31-4b9c-ced6-15eb4e77ed64"
      },
      "source": [
        "# Naive = naive_bayes.MultinomialNB(alpha=alpha)\n",
        "# Naive.fit(Train_X_Tfidf,y_train)\n",
        "\n",
        "Naive = naive_bayes.MultinomialNB(alpha=alpha)\n",
        "Naive.fit(Train_X_Tfidf,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgR1AfUfrG15"
      },
      "source": [
        "**Google Translate results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDYxR5DEe7kc",
        "outputId": "73b9e2b7-4acc-41c2-9de5-8c5db47d4814"
      },
      "source": [
        "# predictions_NB = Naive.predict(test_google_Tfidf)\n",
        "\n",
        "# # result of test for google translate\n",
        "# print(\"result of test for google translate\")\n",
        "# print(classification_report( Test_Y_google, predictions_NB))\n",
        "\n",
        "\n",
        "predictions_NB = Naive.predict(test_mbart_Tfidf)\n",
        "print(\"result of test for MBART translate\")\n",
        "print(classification_report( Test_Y_mbart, predictions_NB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result of test for MBART translate\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.92      1792\n",
            "           1       0.40      0.04      0.08       288\n",
            "\n",
            "    accuracy                           0.86      2080\n",
            "   macro avg       0.63      0.52      0.50      2080\n",
            "weighted avg       0.80      0.86      0.81      2080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htq9JeCXpzj4",
        "outputId": "78cfe456-d7ce-4f59-af6f-d5b56bbc569f"
      },
      "source": [
        "tune_X_google, Test_X_google, tune_Y_google, Test_Y_google"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3214    ['guy', 'monster', 'time', 'pass', 'demon', 'p...\n",
              " 1262    ['late', 'late', 'cable', 'direct', 'czech', '...\n",
              " 2069    ['khbrayn', 'week', 'hell', 'late', 'hdadksyf'...\n",
              " 322     ['know', 'manvk', 'khodabakhshian', 'go', 'mea...\n",
              " 4294    ['reed', 'ya', 'club', 'sorry', 'sorry', 'say'...\n",
              "                               ...                        \n",
              " 4171    ['ready', 'help', 'account', 'number', 'announ...\n",
              " 599           ['simple', 'nemishe', 'little', 'shrewish']\n",
              " 1361    ['pretty', 'cool', 'one', 'hour', 'delete', 'k...\n",
              " 1547    ['nothing', 'never', 'wan', 'na', 'n', 'pituit...\n",
              " 4959                                    ['think', 'like']\n",
              " Name: text_final, Length: 3120, dtype: object,\n",
              " 2593    ['saw', 'people', 'different', 'mhytay', 'reas...\n",
              " 4392    ['regardless', 'aggressiveness', 'support', 'i...\n",
              " 3821       ['every', 'day', 'think', 'alone', 'tomorrow']\n",
              " 4473    ['whether', 'whatever', 'want', 'today', 'isla...\n",
              " 847     ['appearance', 'head', 'face', 'go', 'art', 's...\n",
              "                               ...                        \n",
              " 4803    ['queiroz', 'rvyash', 'money', 'launderers', '...\n",
              " 4974    ['think', 'well', 'month', 'rmzvn', 'time', 'c...\n",
              " 2093    ['sure', 'god', 'man', 'kindness', 'woman', 'e...\n",
              " 1515    ['possibility', 'regime', 'spread', 'rumor', '...\n",
              " 1258    ['jahangiri', 'people', 'iran', 'caspian', 'se...\n",
              " Name: text_final, Length: 2080, dtype: object,\n",
              "       class\n",
              " 3214      1\n",
              " 1262      0\n",
              " 2069      1\n",
              " 322       0\n",
              " 4294      1\n",
              " ...     ...\n",
              " 4171      1\n",
              " 599       1\n",
              " 1361      0\n",
              " 1547      0\n",
              " 4959      0\n",
              " \n",
              " [3120 rows x 1 columns],\n",
              "       class\n",
              " 2593      0\n",
              " 4392      0\n",
              " 3821      0\n",
              " 4473      0\n",
              " 847       0\n",
              " ...     ...\n",
              " 4803      0\n",
              " 4974      0\n",
              " 2093      1\n",
              " 1515      0\n",
              " 1258      0\n",
              " \n",
              " [2080 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-sdatdQ2lP2"
      },
      "source": [
        "**not use english dataset**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfEw_Fbf2qXH"
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=max_features)\n",
        "Tfidf_vect.fit(tune_X_google)\n",
        "Train_X_Tfidf = Tfidf_vect.transform(tune_X_google)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X_google)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzjtVAtg3RD8",
        "outputId": "70a2aa14-ab4d-4a0b-c614-dcca16f85e46"
      },
      "source": [
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,tune_Y_google)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow3UHqh43ljE",
        "outputId": "f9d3b9ba-26bd-415b-cb99-810e271b5041"
      },
      "source": [
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "print(\"test if we dont use english train dataset\")\n",
        "print(classification_report( Test_Y_google, predictions_NB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test if we dont use english train dataset\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92      1792\n",
            "           1       0.14      0.01      0.03       288\n",
            "\n",
            "    accuracy                           0.85      2080\n",
            "   macro avg       0.50      0.50      0.47      2080\n",
            "weighted avg       0.76      0.85      0.80      2080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5AjiFrJ4dcy"
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=max_features)\n",
        "Tfidf_vect.fit(tune_X_mbart)\n",
        "Train_X_Tfidf = Tfidf_vect.transform(tune_X_mbart)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X_mbart)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ajQlJIj5nof",
        "outputId": "4b4b9095-7617-4f7d-e4f0-685fd3441de7"
      },
      "source": [
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "print(\"test if we dont use english train dataset: mbart\")\n",
        "print(classification_report( Test_Y_mbart, predictions_NB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test if we dont use english train dataset: mbart\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92      1792\n",
            "           1       0.14      0.01      0.03       288\n",
            "\n",
            "    accuracy                           0.85      2080\n",
            "   macro avg       0.50      0.50      0.47      2080\n",
            "weighted avg       0.76      0.85      0.80      2080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfjSxY2twvKI"
      },
      "source": [
        ""
      ]
    }
  ]
}